---
title: "ExOpVis"
author: "Galina M. Jönsson"
date: "04/04/2022"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---
<br />

## Introduction

<br />
The purpose of the expert review process is to determine whether the long-term resident butterfly trends produced by our occupancy model formulation are a plausible description of how species changed between 1900-1976, and reflects existing knowledge for species post-1976.
<br />
<br />
The participants completed an online questionnaire which asked them to assess each of 52 graphs depicting 52 species' annual occupancy estimates across Great Britain from 1900 to 2016. For each of the 52 species' graphs, participants were asked two identical questions: to separately score (1) the extent to which estimates (including the uncertainty ribbon) between 1900-1976 were a plausible description of species' trends, and (2) whether the estimates (including the uncertainty ribbon) between 1976-2016 reflect existing knowledge (i.e., before and after UKBMS' standardized monitoring was initiated). All questions were scored on a five point scale (Strongly agree; Agree; Neither agree nor disagree; Disagree; Strongly disagree).  
<br/>
<br/>
Disagreement with an occupancy trend indicates that it is not a plausible description nor/or adequately reflect the evidence for that species. 
<br/>
The **ten** participants scored both periods for each of 52 species' occupancy plots (i.e., 104 questions per participant) for a total of **1,040** answers. These were coded from -2 (Strongly disagree) to +2 (Strongly agree).

<br/>

### Hypotheses

<br/>
We will use the answers from the questionnaire to answer/explore the following hypotheses/statements: 

1. The model formulation inaccurately estimates butterfly occupancy.  
    + If true, we expect that across participants, mean scores for all 52 species and both time periods is zero or lower (i.e., average scores are no better than ‘Neither agree nor disagree’) with high unanimity.   
    + If true, we also expect that the mean scores and the unanimity scores across participants show no significant difference between the 52 species, not between the two time periods.  
    + 'Prescription': re-formulate model or abort mission.   
2. The model formulation accurately estimates occupancy for the later time period (1976-2016), but fails to do so for the early time period (1900-1976). 
    + If true, we expect that across participants, mean scores across all 52 species for the early time period is zero or lower (i.e., no better than ‘Neither agree nor disagree’), while mean scores for the later time period is zero or lower. Specifically, we expect that for each of the 52 individual species, the distance between mean scores across participants is lower for the early compared to the late time period.         
    + If true, we also expect that the mean scores and the unanimity scores across participants show no significant difference between the 52 species.  
    + 'Prescription': re-formulate model or do not use for early time period.   
3. The model formulation accurately estimates occupancy for the early time period, but fails to do so for the late time period. 
   + Like point 2 but 'reverse'
4. The model formulation fails to produce 'accurate/good' outputs for some species, i.e., some species are just hard to model.  
    + If true, we expect that across participants and time periods, mean scores for some, but not all, species is zero or lower (i.e., meaning that the participants average score was no better than ‘Neither agree nor disagree’). Specifically, we expect that the same individual species score poorly OR well (i.e, less than or greater than zero, respectively) for both time periods.
    + If true, we expect that the distance between mean scores across participants for the two time periods is low across all species. 
4. Some species are hard to model in the early time period (1900-1976)  
5. Some species are hard to model in the later time period (1976-2016)      


<br />
```{r format-data, eval=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
# Load required package(s)
require(tidyr)
require(dplyr)

### Read first participant results
ex1 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp01/expertData__2022-03-22_app01.csv")
# Add participant ID number
ex1$ID <- rep("01", 52)
# pivot separate Q1 & Q2 result columns to a single column and an additional name indicating question number. Name data frame 'df'
df <- ex1 %>% 
  pivot_longer(
    cols = starts_with("q"))

### Second participant results
ex2 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp02IK/expertData__2022-04-01_app02.csv")
ex2$ID <- rep("02", 52)
df <- rbind(df, (ex2 %>% # Row bind with 'df'
                   pivot_longer(cols = starts_with("q"))))
### Third participant results
ex3 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp03/expertData__2022-04-01_app03.csv")
ex3$ID <- rep("03", 52)
df <- rbind(df, (ex3 %>% pivot_longer(cols = starts_with("q"))))
### Fourth participant results
ex4 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp04/expertData__2022-02-16_app04.csv")
ex4$ID <- rep("04", 52)
df <- rbind(df, (ex4 %>% pivot_longer(cols = starts_with("q"))))
### Sixth participant results
ex6 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp06/expertData__2022-04-06_app06.csv")
ex6$ID <- rep("05", 52)
df <- rbind(df, (ex6 %>% pivot_longer(cols = starts_with("q"))))
### Eighth participant results
ex8 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp08/expertData__2022-04-04_app08.csv")
ex8$ID <- rep("06", 52)
df <- rbind(df, (ex8 %>% pivot_longer(cols = starts_with("q"))))
### Ninth participant results
ex09 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp09/expertData__2022-04-17_app09.csv")
ex09$ID <- rep("07", 52)
df <- rbind(df, (ex09 %>% pivot_longer(cols = starts_with("q"))))
### Tenth participant results
ex10 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp10/expertData__2022-04-08_app10.csv")
ex10$ID <- rep("08", 52)
df <- rbind(df, (ex10 %>% pivot_longer(cols = starts_with("q"))))
### Twelfth participant results
ex12 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp12/expertData__2022-04-01_app12.csv")
ex12$ID <- rep("09", 52)
df <- rbind(df, (ex12 %>% pivot_longer(cols = starts_with("q"))))
### Thirteenth participant results
ex13 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp13/expertData__2022-04-08_app13.csv")
ex13$ID <- rep("10", 52)
df <- rbind(df, (ex13 %>% pivot_longer(cols = starts_with("q"))))

### re-code responses from -2 (strongly disagree) to +2 (strongly agree)
df$value <- df$value-3

### Enter whether species are HS or WCS
MSI_lookup <- read.csv("../data/auxiliaryData/MSI_lookup.csv")
df <- merge(df, MSI_lookup[, c("CommonName", "HS_WCS")], by.x = "com_name", by.y = "CommonName", all.x = TRUE, all.y = FALSE)
# manually enter for species with differently spelled names
df[df$com_name == "Brimstone", "HS_WCS"] <- "WCS"
df[df$com_name == "Chalk Hill Blue", "HS_WCS"] <- "HS"
df[df$com_name == "Green-veined White", "HS_WCS"] <- "WCS"
df[df$com_name == "Large Heath", "HS_WCS"] <- "HS"
df[df$com_name == "Orange-tip", "HS_WCS"] <- "WCS"
df[df$com_name == "Pearl-bordered Fritillary", "HS_WCS"] <- "HS"
df[df$com_name == "Silver-spotted Skipper", "HS_WCS"] <- "HS"
df[df$com_name == "Silver-studded Blue", "HS_WCS"] <- "HS"
df[df$com_name == "Silver-washed Fritillary", "HS_WCS"] <- "HS"
df[df$com_name == "Small Mountain Ringlet", "HS_WCS"] <- "HS"
df[df$com_name == "Small Pearl-bordered Fritillary", "HS_WCS"] <- "HS"
df[df$com_name == "White-letter Hairstreak", "HS_WCS"] <- "WCS"
```
<br/>
<br/>


## Data Visualisation

Next,we calculated the mean and variance for each participant across questions (i.e. pre-1976 and post-1976) and species, as well as separately for each question (i.e. pre-1976 and post-1976) across the 52 species (Figure 1).
<br/>
<br/>
<br/>
```{r figure1, eval=TRUE, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE}
# Load required package(s)
require(tidyr)
require(dplyr)
require(ggplot2)

### Subset and summarise response data
df2 <- as.data.frame(na.omit(df[, c("ID", "name", "value")]) %>% group_by(ID, name) %>% summarise(Mean = mean(value), Variance = (var(value))))


# Define colour blind friendly palette
cbPalette <- c("#9E0142", "#D53E4F", "#F46D43", "#FDAE61", "#FEE08B", "#E6F598", "#ABDDA4", "#66C2A5", "#3288BD", "#5E4FA2")
cbPalette <- c(#"#000000",  # "#999999", 
               "grey36", "#E69F00", "#009E73", "#66CC99",
               "#F0E442","#56B4E9", "#0072B2",  "#9999CC",
               "#CC79A7", "#D55E00") # , "#9E0142")


### Graph
ggplot() + # Empty ggplot function to allow use of different data sets for plotting 
  geom_line(aes(Mean, Variance, group = ID), df2, color="grey") + # Line between same species' time periods
  geom_point(aes(Mean, Variance, shape=name, size=name, colour=ID), 
             df2, size=4.5, position = "jitter") + 
  scale_shape_manual(name="\nTime Period", 
                     values=c(18,20), 
                     labels = c("1900-1976", "1976-2016")) +
  scale_colour_manual(name="Participant ID", values=cbPalette) +
  labs(x = "Mean",
       y = "Variance") +
       #title ="Figure 1: Mean scores against variance per participant",
       #subtitle = "Summarised across species for both time periods separately and combined") +
  theme(legend.key = element_rect(fill = "white", colour = NA)) +
  theme(panel.background = element_rect(fill = "white", colour = "black")) +
  guides(size = "none",
         shape = guide_legend(order=1),
         colour = guide_legend(order=2)) +
    guides(colour = guide_legend(override.aes = list(shape = c(15,15,15,15,15,15,15,15,15,15),
                                                     size = 3.7))) + 
  theme(text = element_text(size = 14))

#ggsave("../plots/Participant_meanVar.png",width=7,height=4)
```

```{r figure2, eval=TRUE, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE}
require("dplyr")
require("RColorBrewer")
require("R.utils")
require("ggplot2")
require("wesanderson")

# new response column based on multiple conditions:
df_plot <- df %>% mutate(response = 
           case_when(value == -2 ~ "Strongly disagree", 
                     value == -1 ~ "Disagree", 
                     value == 0 ~ "Neither agree nor disagree", 
                     value == 1 ~ "Agree",
                     value == 2 ~ "Strongly agree")
)

names(df_plot)[names(df_plot) == "name"] <- "Period"
df_plot[df_plot$Period=="q1", "Period"] <- "1900-1976"
df_plot[df_plot$Period=="q2", "Period"] <- "1976-2016"

df_plot_wide <- df_plot %>%
	group_by(Period, response) %>%  # grouping by these two variables
	tally() %>%  # counting the number of responses
	mutate(perc = n / sum(n) * 100) %>%
	dplyr::select(-n) %>%
	group_by(Period) %>%
	spread(response, perc)
# Remove NA column
df_plot_wide <- df_plot_wide[,-7]

df_plot_hi_lo <- df_plot_wide %>%
	mutate(midlow = `Neither agree nor disagree` / 2,
		midhigh = `Neither agree nor disagree` / 2) %>%
	dplyr::select(Period, 'Strongly disagree', 'Disagree', midlow, midhigh, 'Agree' , 'Strongly agree') %>%
	gather(key = response, value = perc, 2:7) %>%
	`colnames<-`(c("Period", "response", "perc"))

df_plot_hi <- df_plot_hi_lo %>%
	filter(response %in% c('Strongly agree', 'Agree' , 'midhigh')) %>%
	mutate(response = factor(response, levels = c('Strongly agree', 'Agree' , 'midhigh')))

df_plot_lo <- df_plot_hi_lo %>%
	filter(response %in% c("midlow", "Disagree", "Strongly disagree")) %>%
	mutate(response = factor(response, levels = c("Strongly disagree", "Disagree", "midlow")))

# Use RColorBrewer to store a preset diverging colour palette as a vector of colour codes
#legend_pal <- brewer.pal(name = "RdBu", n = 5)
# Duplicate the middle value since "Neither agree nor disagree" is two groups: "midhigh" and "midlow"
#legend_pal <- insert(legend_pal, ats = 3, legend_pal[3])
# Replace the ugly white colour for "Neither agree nor disagree" with a pleasant dishwater grey
#legend_pal <- gsub("#F7F7F7", "#9C9C9C", legend_pal)
# Assign names to the vector based on the colours we want for each group
#names(legend_pal) <- c('Strongly disagree', 'Disagree', 'midhigh', 'midlow', "Agree", "Strongly agree")

# Use wesanderson to store a preset diverging colour palette as a vector of colour codes
mycols <- wes_palette("Zissou1", n=15, type="continuous")[c(12,8,7,5,1)]
# Duplicate the middle value since "Neither agree nor disagree" is two groups: "midhigh" and "midlow"
mycols <- insert(mycols, ats = 3, wes_palette("Zissou1", n=10, type="continuous")[c(5)])
# Replace the ugly white colour for "Neither agree nor disagree" with a pleasant dishwater grey
mycols <- gsub("#CAC656", "#9C9C9C", mycols)
mycols <- gsub("#D1C74C", "#9C9C9C", mycols)
# Assign names to the vector based on the colours we want for each group
names(mycols) <- c('Strongly disagree', 'Disagree', 'midhigh', 'midlow', "Agree", "Strongly agree")


# Plot
ggplot() +
	geom_bar(data = df_plot_hi, aes(x = Period, y=perc, fill = response), stat="identity") +
	geom_bar(data = df_plot_lo, aes(x = Period, y=-perc, fill = response), stat="identity") +
	geom_hline(yintercept = 0, color =c("black")) +
	scale_fill_manual(values = mycols,
		breaks = c('Strongly agree', 'Agree', 'midhigh', "Disagree", "Strongly disagree"),
		labels = c('Strongly agree', 'Agree', 'Neither agree nor disagree', "Disagree", "Strongly disagree")) +
	coord_flip() +
	labs(x = "Time Period", 
	     y = "Percentage of answers (%)",
       fill = "Response") +
       #title ="Figure 2: Distribution of responses across species and participants") +
	theme_classic() +
  theme(text = element_text(size = 14)) 

ggsave("../plots/Percentage_scores.png",width=7,height=4)
```
<br/>
<br/>
**General trends: Mean Scores**  

* On average across species, all participants score post-1976 trends (diamond) higher than pre-1976 trends (triangle). 
* All but one participants' (ID 09) mean score across the two time periods (circles) are greater than zero meaning that these participants average scores were generally better than ‘Neither agree nor disagree’.<br/>
* All participants, on average, scored post-1976 trends above zero, indicating that generally, there is some level of agreement/plausibility for the late time period. <br/>
* Three of ten participants' mean scores for the 'pre-1976' periods (triangle) are negative (04, 09 and 10), i.e., no better than ‘Neither agree nor disagree’ and instead, more likely to be disagreed, than agreed, with.  <br/>
    + One participant (ID 09) stands out as scoring lower than others across all questions.<br/>
<br/>   

**General trends: Variance**  

* The variance among scores for pre-1976 trends (triangle) are generally greater than for post-1976 trends (diamond). 
* Most participants' difference between pre-1976 trends' (triangle) and post-1976 trends' (diamond) score variances are around, or just above, 0.05; however, three participants relative variance differences deviate from the generality. Namely, ID01, ID06 and ID10, whose answers tend to be more consistent/unanimous to questions on the later time series while answers for the early part of the time series vary more depending on species.<br/>
<br />
<br />
<br />

***
Next, we also calculated the mean and variance for each species across participants, and measured the unanimity across participants as 1-variance (Figure 3).
of the time series vary more depending on species.<br/>
<br />
<br />


```{r figure3, eval=TRUE, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE}
# Load required package(s)
require(tidyr)
require(dplyr)
require(ggplot2)
require(RColorBrewer)

### Constraint Line
constraintLine <- data.frame(nMax = as.numeric(0:10), nMin = as.numeric(10:0),
                             mean = as.numeric(rep(NA, 11)), # To populate
                             unanimity = as.numeric(rep(NA, 11))) # To populate
# Loop through each row with number of possible extremes (2 or -2) 
for(i in 1:nrow(constraintLine)){ # For each row, create a vector with ten (10) elements:
  temp <- append(rep(-2, constraintLine$nMax[[i]]), # nMax times 2 ('Strongly agree')
                 rep(2, constraintLine$nMin[[i]])) # nMin times -2 ('Strongly disagree')
  constraintLine$mean[[i]] <- mean(temp) # Use vector to find mean
  constraintLine$unanimity[[i]] <- 1-var(temp) # and unanimity
}
# constraintLine <- subset(constraintLine, mean>1.1)


### Subset and summarise response data
df3 <- as.data.frame(na.omit(df[, c("spp_name", "name", "value", "HS_WCS")]) %>% group_by(spp_name, name, HS_WCS) %>% summarise(Mean = mean(value), Unanimity = (1 - (var(value)))))

cols <- c("#E69F00", "#009E73")
#cols <- c("#E69F00", "#74A089")


### Graph
ggplot(df3, aes(Mean, Unanimity)) + # Empty ggplot function to allow use of different data sets for plotting 
  geom_line(aes(group = spp_name), color="grey") + # Line between same species' time periods
  geom_jitter(width = 0.04, height = 0.04, aes(group = name, shape=name, colour=name), size=3.5) + # use jitter over geom_points to reveal overlapping points
  geom_line(aes(mean, unanimity), constraintLine) + # Add constraint line
  scale_shape_manual("Time Period", values=c(15, 17),
                     labels = c("1900-1976", "1976-2016")) +
  scale_colour_manual("Time Period", values=cols,
                      labels = c("1900-1976", "1976-2016")) +
  labs(x = "Mean Score", y = "Unanimity") +
  #     title ="Figure 3: Mean scores against unanimity (1- variance)") +
  theme(legend.key = element_rect(fill = "white", color = NA)) +
  theme(panel.background=element_rect(fill="white", colour="black")) +
  coord_cartesian(ylim=c(-1.6, 1)) +
  theme(text = element_text(size = 14))   

#ggsave("../plots/Scores_VS_unanimity.png",width=7,height=4)

########################################################
### Replot this with cluster 2 species in different colou (for other project)
# Define species names
#clust2 <- c("Aglais.urticae", "Anthocharis.cardamines",
#            "Coenonympha.pamphilus", "Lycaena.phlaeas",
#            "Maniola.jurtina", "Ochlodes.sylvanus", 
#            "Pieris.napi", "Pieris.rapae",
#            "Polyommatus.icarus", "Thymelicus.sylvestris")
# Denote these species in data frame
#df3[df3$spp_name%in% clust2, "name"] <- "clust2"
# Define colours and labels
#cols <- c("#800000FF", "#E69F00", "#009E73")
#mylabels <- c("Cluster 2", "1900-1976", "1976-2016")
# Plot
#ggplot(df3, aes(Mean, Unanimity)) + 
#  geom_line(aes(group = spp_name), color="grey") + 
#  geom_jitter(width = 0.04, height = 0.04, aes(group = name, shape=name, colour=name), size=3.5) + 
#  geom_line(aes(mean, unanimity), constraintLine) + 
#  scale_shape_manual("", values=c(19, 15, 17), labels = mylabels) +
#  scale_colour_manual("", values=cols, labels = mylabels) +
#  labs(x = "Mean Score", y = "Unanimity") +
#  theme(legend.key = element_rect(fill = "white", color = NA)) +
#  theme(panel.background=element_rect(fill="white", colour="black")) +
#  coord_cartesian(ylim=c(-1.6, 1)) +
#  theme(text = element_text(size = 14)) 
#ggsave("../plots/ForTrends_leps_Cluster2.png",width=7,height=4)
```
<br/>
<br/>
```{r figure4, eval=TRUE, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE}
# Load required package(s)
require(tidyr)
require(dplyr)
require(ggplot2)
require(RColorBrewer)

### Subset and summarise response data
df3 <- as.data.frame(na.omit(df[, c("spp_name", "name", "value", "HS_WCS")]) %>% group_by(spp_name, name, HS_WCS) %>% summarise(Mean = mean(value), Unanimity = (1 - (var(value)))))

### Bums... to facetwrap I'll need to restructure the df 
# Separate into two dfs
df3mean <- df3[,c("spp_name", "name", "Mean")]
# New column indicating score ID
df3mean$Difference <- 'Mean'
# Rename "Mean_diff" column to identical as Unanimity df (below)
names(df3mean)[names(df3mean) == "Mean"] <- "value"
### Repeat for Unanimity
df3unanimity <- df3[,c("spp_name", "name", "Unanimity")]  
df3unanimity$Difference <- 'Unanimity'
names(df3unanimity)[names(df3unanimity) == "Unanimity"] <- "value"

# combine the two data frames
df3b <- rbind(df3mean, df3unanimity)

names(df3b)[names(df3b) == "name"] <- "period"

df3b[df3b$period=="q1", "period"] <- "1900-1976"
df3b[df3b$period=="q2", "period"] <- "1976-2016"
  
ggplot(df3b, aes(value, group = spp_name)) + geom_histogram(bins = 15, aes(fill = spp_name))  + 
  facet_grid(period ~ Difference ) +
  #facet_wrap(~ Difference) +
  labs(x = "Score", y = "Count",
       title ="Figure 4: Mean scores and unanimity scores by time period",
       subtitle = "Coloured by species (pretty ugly btf...)") +
  theme(legend.key = element_rect(fill = "white", color = NA)) +
  theme(panel.background=element_rect(fill="white", colour="black")) +
  theme(legend.position="none") +
  scale_fill_hue(c=45, l=80) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, NA)) +
  theme(text = element_text(size = 12))  



ggplot(df3b, aes(value, group = spp_name)) + geom_histogram(bins = 15)  + 
  facet_grid(period ~ Difference ) +
  #facet_wrap(~ Difference) +
  labs(x = "Score", y = "Species") +
   #    title ="Figure 4: Mean scores and unanimity scores by time period") +
  theme(legend.key = element_rect(fill = "white", color = NA)) +
  theme(panel.background=element_rect(fill="white", colour="black")) +
  theme(legend.position="none") +
  scale_fill_hue(c=45, l=80) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, NA)) +
  theme(text = element_text(size = 14))  
```
<br />
<br />
<br />
<br />
<br />
**General trends:**  

* 16 of the 104 questions have a mean score of zero or lower meaning that the participants average score was no better than ‘Neither agree nor disagree’. 
    + 15 of the 16 were 'pre-1976'-questions; only 1 concerned the post-1976 time period, specifically, *Polyommatus coridon*  (i.e., Chalk Hill Blue). <br/>
    + Ten and six questions concerned WCSs and HSs, respectively.<br />
* Five species' time periods on the top left-hand side of Figure 3 have a mean score of -1 or lower and high unanimity scores indicating low divergence of opinion among participants. These are all WSCs, specifically: <br />
    1. Small Tortoiseshell (*Aglais urticae*) <br/>
    2. Green-veined White (*Pieris napi*) <br/>
    3. Small White (*Pieris rapae*) <br/>
    4. Common Blue (*Polyommatus icarus*) <br/>
    5. Meadow Brown (*Maniola jurtina*) <br/>
<br/>
* As for the criterion/cut off point beyond which we won't include model outputs: Instead of discarding, let's say, species' model outputs with mean scores of -1 or less, perhaps a 'stronger' way of presenting it would be to say e.g.:
    + First, all species' model outputs with a mean agreement score of less than 0 are **considered** for exclusion (because these indicate trends worse than ‘Neither agree nor disagree’). <br/>
    + Second, we only discard species/model outputs when there is high unanimity among participants (because this is strong evidence for something being wrong; however, if unanimity is low although the mean score falls below 0, most participants may have answered 'Disagree', whilst the one-two expert(s) on that specific species answered 'Strongly agree'). 
<br/>
<br/>
<br/>

*** 
Next, we investigate whether there is evidence suggesting that some species' trends are easier to model for both time periods, the early or the late period by visualising the distance between each species' late- and early period mean scores, as well as unanimity scores. 
<br/>
<br/>
<br/>
```{r figure5a, eval=TRUE, echo=FALSE, cache=TRUE}
# Load required package(s)
require(dplyr)
require(ggplot2)

# Vectorise species' names
spp <- as.factor(unique(df3$spp_name))

# Empty data frame to populate
df4 <- data.frame(spp_name = spp,
                  name = as.character(rep("Difference"), 52),
                  Mean_diff = as.numeric(rep(NA, 52)),
                  Unanimity_diff = as.numeric(rep(NA, 52)))

# Loop through species and subtract post-1976 scores from pre-1976 scores
for(i in 1:length(spp)){
  temp <- df3[df3$spp_name == paste0(spp[i]), ]
  df4[df4$spp_name == paste0(spp[i]), "Mean_diff"] <- ((temp[temp$name == "q1",]$Mean) - (temp[temp$name == "q2",]$Mean))
  df4[df4$spp_name == paste0(spp[i]), "Unanimity_diff"] <- ((temp[temp$name == "q1",]$Unanimity) - (temp[temp$name == "q2",]$Unanimity))
}

### To facetwrap I'll need to restructure the df 
# Separate into two dfs
df4mean <- df4[,c("spp_name", "name", "Mean_diff")]
# New column indicating score ID
df4mean$Difference <- 'Mean'
# Rename "Mean_diff" column to identical as Unanimity df (below)
names(df4mean)[names(df4mean) == "Mean_diff"] <- "value"
### Repeat for Unanimity
df4unanimity <- df4[,c("spp_name", "name", "Unanimity_diff")]
df4unanimity$Difference <- 'Unanimity'
names(df4unanimity)[names(df4unanimity) == "Unanimity_diff"] <- "value"

# combine the two data frames
df4 <- rbind(df4mean, df4unanimity)
names(df4)[names(df4) == "name"] <- "period"

# combine the two data frames
df_test2 <- rbind(df4, df3b)



ggplot(df_test2, aes(value, group = spp_name)) + geom_histogram(bins = 14)  + 
  facet_grid(period ~ Difference ) +
  #facet_wrap(~ Difference) +
  labs(x = "Score", y = "Species") +
   #    title ="Figure 4: Mean scores and unanimity scores by time period") +
  theme(legend.key = element_rect(fill = "white", color = NA)) +
  theme(panel.background=element_rect(fill="white", colour="black")) +
  theme(legend.position="none") +
  scale_fill_hue(c=45, l=80) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, NA)) +
  theme(text = element_text(size = 14))  
```


```{r figure5b, eval=TRUE, echo=FALSE, results='asis', cache=TRUE}
require("knitr")
df4mean <- df4mean[,c("spp_name","value")]
kable(head(df4mean[order(df4mean$value, decreasing = TRUE), ]), caption = "Lowest distances between pre-1976 vs. post-1976 mean scores")
kable(tail(df4mean[order(df4mean$value, decreasing = TRUE), ]), caption = "Highest distances between pre-1976 vs. post-1976 mean scores")

df4unanimity <- df4unanimity[,c("spp_name","value")]
kable(head(df4unanimity[order(df4unanimity$value, decreasing = TRUE), ]), caption = "Lowest distances between pre-1976 vs. post-1976 unanimity scores")
kable(tail(df4unanimity[order(df4unanimity$value, decreasing = TRUE), ]), caption = "Highest distances between pre-1976 vs. post-1976 unanimity scores")
```

<br />
<br />
**General trends:**  

* Nearly all 'approval' and unanimity scores are higher for post-1976 trends compared to pre-1976 trends. 
* The mean themselves are not bell curved but we can see that the difference between points is! EXCEPT for the few species to the right 

**<span style="color: red;">Galina: Finish text and tidy head&tail tables</span>**

***
Before moving on to the next step, we remind ourselves what the plots for the five most poorly rated species' trends look like
```{r figure6, eval=TRUE, echo=FALSE, cache=TRUE, message=FALSE}
# Load required package(s)
require(png)
# Load png picture files
A_urticae <- readPNG(source="../app_ExpertReviewForm/app_ExpertReviewForm/data/Aglais.urticae.png")
P_napi <- readPNG(source="../app_ExpertReviewForm/app_ExpertReviewForm/data/Pieris.napi.png")
P_rapae <- readPNG(source="../app_ExpertReviewForm/app_ExpertReviewForm/data/Pieris.rapae.png")
P_icarus <- readPNG(source="../app_ExpertReviewForm/app_ExpertReviewForm/data/Polyommatus.icarus.png")
M_jurtina <- readPNG(source="../app_ExpertReviewForm/app_ExpertReviewForm/data/Maniola.jurtina.png")

# create empty plot
plot(NA, xlim = c(0, 2.4), ylim = c(0, 5.5), main="Figure 6: Occupancy plots for the species with least plausible trends 1900-1976 ", cex.main=1, type = "n", xaxt = "n", yaxt = "n", xlab = "", ylab = "")
#Populate with png pics
rasterImage(A_urticae, 0, 3, 0.8, 5.5)
rasterImage(P_napi, 0.8, 3, 1.6, 5.5)
rasterImage(P_rapae, 1.6, 3, 2.4, 5.5)
rasterImage(P_icarus, 0, 0, 0.8, 2.5)
rasterImage(M_jurtina, 0.8, 0, 1.6, 2.5)
#add text
text(0.45,5.4, "Aglais urticae", cex=0.9, col="black", font = 3)
text(1.25,5.4, "Pieris napi", cex=0.9, col="black", font = 3)
text(2.05,5.4, "Pieris rapae", cex=0.9, col="black", font = 3)
text(0.45,2.5, "Polyommatus icarus", cex=0.9, col="black", font = 3)
text(1.25,2.5, "Maniola jurtina", cex=0.9, col="black", font = 3)
```
<br/>
Yes, confirmed. They look off. 


*** 
Let's take a closer look at the species with low unanimity indicating high divergence of opinion among participants to potentially find whether it's driven by one participant's answer (and could be a potential outlier/mistake to follow up on) or 'genuine' disagreement among the participants. 
<br/>

We use a box plot to visualise the distribution of scores for species and time period combinations where the unanimity score is less than zero, only including combinations with outliers to more easily see the most extreme cases (Figure 6). Combinations without outliers are discarded as 'genuine' disagreement among the participants.   
<br/>
<br/>
<br/>
```{r figure7, eval=TRUE, echo=FALSE, cache=TRUE}
# Load required package(s)
require(tidyr)
require(dplyr)
require(ggplot2)

# Subset species' periods where unanimity scores are less than 0
df5lookup <- subset(df3, Unanimity < 0)
df5lookup$lookup <- paste0(df5lookup$spp_name, "_", df5lookup$name)


### Subset and summarise response data
df5 <- na.omit(df[, c("spp_name", "name", "value", "HS_WCS")])
df5$lookup <- paste0(df5$spp_name, "_", df5$name)
df5 <- df5[df5$lookup %in% df5lookup$lookup, ]
df5[df5$name=="q1", "name"] <- "Pre1976"
df5[df5$name=="q2", "name"] <- "Post1976"
df5$lookup <- paste0(df5$spp_name, "_", df5$name)


#df5 %>% 
#  ggplot(aes(x=lookup, y=value)) +
#  geom_boxplot(outlier.colour = "red") +
#  labs(x = "Species & time period", y = "Agreement Scores",
#       title ="Figure 4: Distribution of scores",
#       subtitle = "For species and time periods where unanimity is less than 0") +
#  theme(panel.background=element_rect(fill="white", colour="black")) +
#  coord_flip() +
#  theme(text = element_text(size = 12)) 


df6<-df5[!(df5$lookup=="Satyrium.w-album_Post1976" | 
             df5$lookup=="Pyrgus.malvae_Post1976" | 
             df5$lookup=="Polyommatus.icarus_Post1976" | 
             df5$lookup=="Polyommatus.coridon_Pre1976" | 
             df5$lookup=="Polyommatus.coridon_Post1976" | 
             df5$lookup=="Plebejus.argus_Pre1976" | 
             df5$lookup=="Melitaea.cinxia_Pre1976"|
             df5$lookup=="Lycaena.phlaeas_Post1976" | 
             df5$lookup=="Limenitis.camilla_Post1976" | 
             df5$lookup=="Hipparchia.semele_Post1976" | 
             df5$lookup=="Euphydryas.aurinia_Pre1976" | 
             df5$lookup=="Euphydryas.aurinia_Post1976" | 
             df5$lookup=="Erebia.epiphron_Pre1976" | 
             df5$lookup=="Callophrys.rubi_Post1976" | 
             df5$lookup=="Boloria.selene_Pre1976" | 
             df5$lookup=="Aglais.io_Pre1976"),]


df6 %>% 
  ggplot(aes(x=lookup, y=value)) +
  geom_boxplot(outlier.colour = "red") +
  labs(x = "Species & time period", y = "Agreement Scores",
       title ="Figure 7: Distribution of scores",
       subtitle = "For species and time periods with unanimity<0 and outliers ") +
  theme(panel.background=element_rect(fill="white", colour="black")) +
  coord_flip() +
  theme(text = element_text(size = 12)) 
```
<br />
<br />
The following six species:time period combinations stand out:

* Thymelicus.lineola_Pre1976: 
    + -2 'Strongly disagree' (ID10) <br/>
* Plebejus.argus_Post1976: 
    + -2 'Strongly disagree' (ID09) <br/>
* Melitaea.athalia_Post1976: 
    + -2 'Strongly disagree' (ID09) <br/>
* Erynnis.tages_Post1976: 
    + -2 'Strongly disagree' (ID09) <br/>
* Celastrina.argiolus_Post1976: 
    + -2 'Strongly disagree' (ID05) <br/>
* Anthocharis.cardamines_Pre1976: 
    + -2 'Strongly disagree' (ID04) <br/>

Three of six 'extremes' are driven by participant ID 09, who stands out as scoring lower than others across all questions (Figure 1) and we therefore expect these to be 'genuine'. The remaining three 'extremes' are responses by three separate participants (04, 05 and 10), neither of which clearly stands out from participants (Figure 1). To investigate whether these may be genuine mistakes, we use a modelling approach (see next sub-section).

<br />
<br />
<br />
<br />
<br />
<br />

## Linear Mixed-Effects Model

<br />
We use mixed effects models to seek more definitive answers to the questions above figures suggest. 

### Model Selection

First, we fit two models with identical fixed and random effect structures, but different distributions
(Normal (Gaussian)) and Poisson, and determine which distribution family best explains the data distribution.   

<br />
```{r generate-models, message=FALSE, eval=TRUE, echo=TRUE, cache=TRUE}
# Load required package(s)
require(lme4)

# First we give the raw data frame more informative names
df <- na.omit(df[, c("spp_name", "ID", "name", "value", "HS_WCS")])
colnames(df) <- c("spp_name", "ID", "period", "score", "HS_WCS")
df[df$period=="q1", "period"] <- "Pre1976"
df[df$period=="q2", "period"] <- "Post1976"

### re-code responses back to 1-5 scale (Poisson cannot handle negative values)
df$score <- df$score+3

### generate models with same random effect structure but different distributions
# Normal (Gaussian) 
lmerNormal <- lmer(score ~ period + (1|spp_name) + (1|ID), data = df)
# Poisson
glmerPoisson <- glmer(score ~ period + (1|spp_name) + (1|ID), 
                      data = df, family = poisson)

# compare models
anova(glmerPoisson, lmerNormal, test = "Chisq")
```
<br/>
<br/>
<br/>
The model comparison shows that the normal (Gaussian) model has a significantly better fit to the data compared with the Poisson model because:

* AIC decreases
* BIC decreases
* The p-value << 0.05
<br/>

### Time period (fixed) effect

We will therefore continue with the normal (Gaussian) model. First, we  re-code response scores back to the -2 to 2 scale because normal (Gaussian) models can handle negative values whilst Poisson's cannot. We'll then inspect the model output, test whether the fixed effect is significant (i.e. whether scores for the two time periods differ) and plot the results. 
<br/>
```{r test-fixed-effect-plot6, message=FALSE, eval=TRUE, echo=TRUE, cache=TRUE}
# Load required package(s)
require(lme4)
require(glmmTMB)
require(car)
require(effects)

#re-code responses back to 1-5 scale
df$score <- df$score-3

# Re-generate the Normal (Gaussian) models with sre-coded scores
lmerNormal <- lmer(score ~ period + (1|spp_name) + (1|ID), data = df)

# inspect results
summary(lmerNormal)
car::Anova(lmerNormal)

# Plot results
effects_ok <- (requireNamespace("effects") && getRversion() >= "3.6.0")
if (effects_ok) {
plot(allEffects(lmerNormal) )
}
```
<br/>
<br/>
The type II Wald chisquare test shows that scores for Pre-1976 trends are significantly lower than post-1976 scores: on average, pre-1976 trends' scores are 0.70428 lower than post-1976. Plots and error bars agree. We now look into a few different model diagnostics to decipher what's up with our random effect. 
<br/>
<br/>

### Participant and species ID (random) effects


**Useful resources:**
* https://slcladal.github.io/regression.html#2_Mixed-Effects_Regression  
* Book: J. C. Pinheiro & D. M. Bates. 2000. *Mixed-Effects Models in S and S-PLUS*, **Chapter 1.1**. Springer.

<br/>
First, we generate diagnostic plots that focus on the random effect structure.

```{r diagnostics1, message=FALSE, eval=TRUE, echo=TRUE, cache=TRUE}
require(ggplot2)
require(lattice)

# "Draw quantile-Quantile plots of a sample against a theoretical distribution, possibly conditioned on other variables."

# Generate random effects
rr1 <- ranef(lmerNormal)
par(mfrow=c(2,2))
dotplot(rr1)  ## default
qqmath(rr1)
```
<br />
<br />
<br />
**General trends:**  

* There appear to be differences among both participants and species. 
    + *Participants*: Two extremes are 09 and 06, which tend to score low and high, respectively, accross species and time series. <br/>
    + *Species*: also look as if some are generally 'easier', whilst others are 'hard', to model for both time periods as evident from some scoring high and other low accross periods and participants. WHich are admittedly hard to see on these plots so let's move on. <br/>

***

<br/>
<br/>
```{r diagnostics2, message=FALSE, eval=TRUE, echo=TRUE, cache=TRUE}
plot(lmerNormal, ID ~ resid(.), abline = 0, 
     ylab ="Participant ID", xlab = "Residuals") # generate diagnostic plots
plot(lmerNormal, spp_name ~ resid(.), abline = 0, 
     ylab ="Species", xlab = "Residuals") # generate diagnostic plots
```
<br/>
<br/>
The plots show that there are some outliers (points outside the boxes) and that the variability differs between both participants and species; we therefore examine both participants' and species' standardized residuals (or Pearson’s residuals) versus fitted values in isolation.

* Note the -3 residual for participant 05 (suspected mistake; Figure 6). 
* Neither participant 04 nor 10 (also suspected mistakes; Figure 6) look like they have 'extreme' residuals. <br/>

***

<br/>


```{r diagnostics3, message=FALSE, eval=TRUE, echo=TRUE, cache=TRUE}

plot(lmerNormal, resid(., type = "pearson") ~ fitted(.) | ID, id = 0.05, 
     adj = -0.3, pch = 20, col = "gray40", 
     ylab ="Standardized (Pearson’s) Residuals", xlab = "Fitted Values")
plot(lmerNormal, resid(., type = "pearson") ~ fitted(.) | spp_name, id = 0.05, 
     adj = -0.3, pch = 20, col = "gray40", 
     ylab ="Standardized (Pearson’s) Residuals", xlab = "Fitted Values")
```

<br/>
<br/>


The plots show the standardized residuals (or Pearson’s residuals) versus fitted values and suggests that there are outliers in the data (the names elements in the plots; admittedly, this is rather hard to see for the species).


***




<br/>
<br/>




## Principal Component Analysis



```{r format-data2, eval=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
########################################################
###### Not sure why the PCA struggles to knit - will reload data ###########
########################################################
# Load required package(s)
require(tidyr)
require(dplyr)

### Read first participant results
ex1b <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp01/expertData__2022-03-22_app01.csv")
# Add participant ID number
ex1b$ID <- rep(1, 52)
dfb <- ex1b %>% pivot_longer(cols = starts_with("q"))

### Second participant results
ex2b <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp02IK/expertData__2022-04-01_app02.csv")
ex2b$ID <- rep(2, 52)
dfb <- rbind(dfb, (ex2b %>% pivot_longer(cols = starts_with("q"))))
### Third participant results
ex3b <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp03/expertData__2022-04-01_app03.csv")
ex3b$ID <- rep(3, 52)
dfb <- rbind(dfb, (ex3b %>% pivot_longer(cols = starts_with("q"))))
### Fourth participant results
ex4b <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp04/expertData__2022-02-16_app04.csv")
ex4b$ID <- rep(4, 52)
dfb <- rbind(dfb, (ex4b %>% pivot_longer(cols = starts_with("q"))))
### Sixth participant results
ex6b <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp06/expertData__2022-04-06_app06.csv")
ex6b$ID <- rep(5, 52)
dfb <- rbind(dfb, (ex6b %>% pivot_longer(cols = starts_with("q"))))
### Eighth participant results
ex8b <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp08/expertData__2022-04-04_app08.csv")
ex8b$ID <- rep(6, 52)
dfb <- rbind(dfb, (ex8b %>% pivot_longer(cols = starts_with("q"))))
### Ninth participant results
ex09b <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp09/expertData__2022-04-17_app09.csv")
ex09b$ID <- rep(7, 52)
dfb <- rbind(dfb, (ex09b %>% pivot_longer(cols = starts_with("q"))))
### Tenth participant results
ex10b <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp10/expertData__2022-04-08_app10.csv")
ex10b$ID <- rep(8, 52)
dfb <- rbind(dfb, (ex10b %>% pivot_longer(cols = starts_with("q"))))
### Twelfth participant results
ex12b <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp12/expertData__2022-04-01_app12.csv")
ex12b$ID <- rep(9, 52)
dfb <- rbind(dfb, (ex12b %>% pivot_longer(cols = starts_with("q"))))
### Thirteenth participant results
ex13b <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp13/expertData__2022-04-08_app13.csv")
ex13b$ID <- rep(10, 52)
dfb <- rbind(dfb, (ex13b %>% pivot_longer(cols = starts_with("q"))))

### re-code responses from -2 (strongly disagree) to +2 (strongly agree)
dfb$value <- dfb$value-3

### Enter whether species are HS or WCS
MSI_lookup <- read.csv("../data/auxiliaryData/MSI_lookup.csv")
dfb <- merge(dfb, MSI_lookup[, c("CommonName", "HS_WCS")], by.x = "com_name", by.y = "CommonName", all.x = TRUE, all.y = FALSE)
# manually enter for species with differently spelled names
dfb[dfb$com_name == "Brimstone", "HS_WCS"] <- "WCS"
dfb[dfb$com_name == "Chalk Hill Blue", "HS_WCS"] <- "HS"
dfb[dfb$com_name == "Green-veined White", "HS_WCS"] <- "WCS"
dfb[dfb$com_name == "Large Heath", "HS_WCS"] <- "HS"
dfb[dfb$com_name == "Orange-tip", "HS_WCS"] <- "WCS"
dfb[dfb$com_name == "Pearl-bordered Fritillary", "HS_WCS"] <- "HS"
dfb[dfb$com_name == "Silver-spotted Skipper", "HS_WCS"] <- "HS"
dfb[dfb$com_name == "Silver-studded Blue", "HS_WCS"] <- "HS"
dfb[dfb$com_name == "Silver-washed Fritillary", "HS_WCS"] <- "HS"
dfb[dfb$com_name == "Small Mountain Ringlet", "HS_WCS"] <- "HS"
dfb[dfb$com_name == "Small Pearl-bordered Fritillary", "HS_WCS"] <- "HS"
dfb[dfb$bcom_name == "White-letter Hairstreak", "HS_WCS"] <- "WCS"
```



```{r pca-temp, message=FALSE, warning=FALSE, eval=TRUE, echo=TRUE}
# Load required package(s)
require("tidyr"); require("dplyr"); require("vegan"); require("ggplot2"); require("ggfortify"); require("cluster"); require("factoextra"); require("ggpubr")

# First we give the raw data frame more informative names
df_pca <- na.omit(dfb[, c("rand_id", "spp_name", "ID", "name", "value")])
colnames(df_pca) <- c("spp_id", "spp_name", "participantID", "period", "score")

# new response column based on multiple conditions:
df_pca <- df_pca %>% mutate(period2 = 
           case_when(period == "q1" ~ 1, 
                     period == "q2" ~ 2))

# Define metrics to use
metrics <- c("spp_id", "score", "period2", "participantID")

# Centre and scale metrics
mypr <- prcomp(df_pca[ , metrics], center = T, scale = T)
summary(mypr)
# As an be seen in the elbow method, the first three components are explained as 83% of variance whereas 85% of variance is needed for PCA analysis so we'll need 4 clusters

var <- get_pca_var(mypr)
# See contribution of variables
head(var$cos2, 4)
### The most contributing variables in dimension 1 is .score and period2, whilst the most contributiing for in dimension 2&3 are spp_id and participantID



fviz_pca_biplot(mypr, 
                # Fill individuals by groups
                geom.ind = as.factor("point"),
                addEllipses = TRUE, label = "var",
                pointshape = 21,
                pointsize = 2.5,
                fill.ind = as.factor(df_pca$period2),
                col.ind = as.factor("black"),
                # Color variable by groups
                col.var = factor(c("spp_id", "score", "period2", "participantID")),
                
                
                legend.title = list(fill = "Period", color = "Clusters"),
                repel = TRUE        # Avoid label overplotting
)+ggpubr::fill_palette("jco")+      # Indiviual fill color
  ggpubr::color_palette("npg")      # Variable colors







# select PCA values and create a new dataframe
comp <- data.frame(mypr$x[,1:4])
# Cluster number by euclidian distance metric
fviz_nbclust(comp, kmeans, method = "silhouette") + theme_classic()

k <- kmeans(comp, 8, nstart=25, iter.max=1000)
library(RColorBrewer)
palette(alpha(brewer.pal(9,'Set1'), 0.5))
plot(comp, col=k$clust, pch=16)

summary(k)

table(k$cluster)

sile<-silhouette(k$cluster, dist(comp))

fviz_silhouette(sile)


# Centre and scale metrics
df_pca1 <- decostand(df_pca[ , metrics], "stand")

# Run PCA
temp.pca2 <- prcomp(df_pca1)
tem.km <- cascadeKM(df_pca1, # data
                    inf.gr = 2, # minimum number of groups
                    sup.gr = 5, # maximum number of groups
                    iter = 100, # iterations
                    criterion = "ssi") # Simple Structure Index to identify the optimal number of clusters
ssi.best <- as.numeric(which.max(tem.km$results[2,])) # Find optimal number of clusters
# 4

### Graph
autoplot(kmeans(df_pca1, 4), data = df_pca1,
         loadings = TRUE, loadings.colour = 'black',
         loadings.label = TRUE, loadings.label.size = 3, shape = df_pca$period2) +
  labs(title ="Figure PCA.1: species, score, time period & participant") + 
  scale_shape_manual("Period", values=c(18, 19),
                     labels = c("Pre-1976", "Post-1976")) +
  theme(text = element_text(size = 12))   

# Find average silhouette width
km.res <- kmeans(df_pca1, 4)
ss <- silhouette(km.res$cluster, dist(df_pca1))
mean(ss[, 3]) # 0.2541715
```
<br/>
<br/>

**General trends**

* The simple structure index revealed that the optimal number of k-means clusters is 4 when including species ID, score, time period & participant ID as metrics (Figure PCA.1.), but clusters were poorly supported by the data according to the average silhouette widths (0.254). 
* The vectors for time period and score are practically overlapping, indicating that they are highly positively correlated. Moreover, they strongly influence PC1.  
* Similarly, participant and species are positively correlated, but not to the high degree we see for time period and score, and they influence PC2.  
* On the other hand, time period and score are not correlated with participant and species.  




**Look into further**

* Center and scale metrics as "stand" -> correct? 

<br/>
<br/>
```{r pca-tempb, message=FALSE, warning=FALSE, eval=TRUE, echo=FALSE}
# Load required package(s)
require("tidyr"); require("dplyr"); require("vegan"); require("ggplot2"); require("ggfortify"); require("cluster")

# Define metrics to use
metrics2 <- c("spp_id", "score", "participantID")


# Centre and scale metrics
mypr2 <- prcomp(df_pca[ , metrics2], center = T, scale = T)
summary(mypr2)
# As it can be seen in the elbow method, the first three components are explained as 83% of variance whereas 85% of variance is needed for PCA analysis so we'll need 4 clusters

var2 <- get_pca_var(mypr2)
# See contribution of variables
head(var2$cos2, 3)



fviz_pca_biplot(mypr2, 
                # Fill individuals by groups
                geom.ind = as.factor("point"),
                addEllipses = TRUE, label = "var",
                pointshape = 21,
                pointsize = 2.5,
                fill.ind = as.factor(df_pca$period2),
                col.ind = as.factor("black"),
                # Color variable by groups
                col.var = factor(c("spp_id", "score", "participantID")),
                
                
                legend.title = list(fill = "Period", color = "Clusters"),
                repel = TRUE        # Avoid label overplotting
)+ggpubr::fill_palette("jco")+      # Indiviual fill color
  ggpubr::color_palette("npg")      # Variable colors



# Centre and scale metrics
df_pca2 <- decostand(df_pca[ , metrics2], "stand")

# Run PCA
temp.pca3 <- prcomp(df_pca2)
tem.km2 <- cascadeKM(df_pca2, # data
                    inf.gr = 2, # minimum number of groups
                    sup.gr = 5, # maximum number of groups
                    iter = 100, # iterations
                    criterion = "ssi") # Simple Structure Index to identify the optimal number of clusters
ssi.best <- as.numeric(which.max(tem.km2$results[2,])) # Find optimal number of clusters
# 4

### Graph
autoplot(kmeans(df_pca2, 3), data = df_pca2,
         loadings = TRUE, loadings.colour = 'black',
         loadings.label = TRUE, loadings.label.size = 3, shape = df_pca$period2) +
  labs(title ="Figure PCA.2: species, score & participant") + 
  scale_shape_manual(values=c(20, 21)) + #,
                   #  labels = c("Pre-1976", "Post-1976")) +
  theme(text = element_text(size = 12))   

# Find average silhouette width
km.res2 <- kmeans(df_pca2, 2)
ss2 <- silhouette(km.res2$cluster, dist(df_pca2))
mean(ss2[, 3])# 0.2517791
```

<br/>
<br/>



<br/>
<br/>

## Network Analysis



